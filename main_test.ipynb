{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellima/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/gabriellima/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/imputer_old.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.numeric_features] = X[self.numeric_features].apply(pd.to_numeric, errors='coerce')\n",
      "/Users/gabriellima/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1156, 28)\n",
      "3\n",
      "(1156, 40)\n",
      "(244, 28)\n",
      "3\n",
      "(244, 39)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['39'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 107\u001b[0m\n\u001b[1;32m    104\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m full_pipeline\u001b[38;5;241m.\u001b[39mfit_transform(X_train_transformed)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Aplicando o pipeline nos dados de teste\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mfull_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_clean\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:903\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    901\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[0;32m--> 903\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/imputer_old.py:260\u001b[0m, in \u001b[0;36mBinaryScalerTransformer.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Aplicar o scaler nas colunas não binárias\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_binary_cols] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnon_binary_cols\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['39'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler # it is not affected by outliers.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, RFECV\n",
    "# from imputer import create_full_pipeline\n",
    "from imputer_old import create_full_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "data_original = pd.read_csv('Assets/Data/welddb.csv', delimiter='\\s+', header=None)\n",
    "\n",
    "data = data_original.copy().replace({\"N\": np.nan})\n",
    "\n",
    "# Name the columns\n",
    "data.columns = [\n",
    "    'Carbon concentration (weight%)', \n",
    "    'Silicon concentration (weight%)', \n",
    "    'Manganese concentration (weight%)', \n",
    "    'Sulphur concentration (weight%)', \n",
    "    'Phosphorus concentration (weight%)', \n",
    "    'Nickel concentration (weight%)', \n",
    "    'Chromium concentration (weight%)', \n",
    "    'Molybdenum concentration (weight%)', \n",
    "    'Vanadium concentration (weight%)', \n",
    "    'Copper concentration (weight%)', \n",
    "    'Cobalt concentration (weight%)', \n",
    "    'Tungsten concentration (weight%)', \n",
    "    'Oxygen concentration (ppm by weight)', \n",
    "    'Titanium concentration (ppm by weight)', \n",
    "    'Nitrogen concentration (ppm by weight)', \n",
    "    'Aluminium concentration (ppm by weight)', \n",
    "    'Boron concentration (ppm by weight)', \n",
    "    'Niobium concentration (ppm by weight)', \n",
    "    'Tin concentration (ppm by weight)', \n",
    "    'Arsenic concentration (ppm by weight)', \n",
    "    'Antimony concentration (ppm by weight)', \n",
    "    'Current (A)', \n",
    "    'Voltage (V)', \n",
    "    'AC or DC', \n",
    "    'Electrode positive or negative', \n",
    "    'Heat input (kJ/mm)', \n",
    "    'Interpass temperature (°C)', \n",
    "    'Type of weld', \n",
    "    'Post weld heat treatment temperature (°C)', \n",
    "    'Post weld heat treatment time (hours)', \n",
    "    'Yield strength (MPa)', \n",
    "    'Ultimate tensile strength (MPa)', \n",
    "    'Elongation (%)', \n",
    "    'Reduction of Area (%)', \n",
    "    'Charpy temperature (°C)', \n",
    "    'Charpy impact toughness (J)', \n",
    "    'Hardness (kg/mm2)', \n",
    "    '50% FATT', \n",
    "    'Primary ferrite in microstructure (%)', \n",
    "    'Ferrite with second phase (%)', \n",
    "    'Acicular ferrite (%)', \n",
    "    'Martensite (%)', \n",
    "    'Ferrite with carbide aggregate (%)', \n",
    "    'Weld ID'\n",
    "]\n",
    "\n",
    "# Definição das colunas categóricas e numéricas\n",
    "categoric_features = ['AC or DC', 'Electrode positive or negative', 'Type of weld']\n",
    "numeric_features = ['Sulphur concentration (weight%)', 'Nickel concentration (weight%)', \n",
    "                    'Silicon concentration (weight%)', 'Phosphorus concentration (weight%)', \n",
    "                    'Titanium concentration (ppm by weight)', 'Nitrogen concentration (ppm by weight)', \n",
    "                    'Oxygen concentration (ppm by weight)', 'Voltage (V)', 'Heat input (kJ/mm)']\n",
    "\n",
    "# Separação dos dados em treino e teste\n",
    "X = data.drop(columns = [\"Yield strength (MPa)\", \"Weld ID\"])\n",
    "y = data[\"Yield strength (MPa)\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Criando o pipeline com as features necessárias\n",
    "percent_n_sorted = X_train.isna().mean().sort_values(ascending=False)\n",
    "full_pipeline = create_full_pipeline()\n",
    "\n",
    "# Dropping missing values in test\n",
    "X_test_clean = X_test[~y_test.isna()]\n",
    "y_test_clean = y_test.dropna().astype(float)\n",
    "\n",
    "# Aplicando o pipeline nos dados de treino\n",
    "X_train_transformed = X_train.copy()\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train_transformed)\n",
    "\n",
    "# Aplicando o pipeline nos dados de teste\n",
    "X_test_transformed = full_pipeline.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_features = ['AC or DC', 'Electrode positive or negative', 'Type of weld']\n",
    "\n",
    "data['Type of weld'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um modelo base (nesse caso, um RandomForest)\n",
    "# base_model = RandomForestClassifier()\n",
    "base_model = LabelSpreading(kernel='knn', n_neighbors=7)\n",
    "\n",
    "# Criar o modelo de auto-treinamento\n",
    "self_training_model = SelfTrainingClassifier(base_model)\n",
    "\n",
    "# X_train contém todas as variáveis explicativas\n",
    "# y_train contém os labels, mas com valores NaN para os rótulos faltantes\n",
    "# Importante: O SelfTrainingClassifier trata os valores faltantes como -1, então convertemos NaN para -1\n",
    "y_train_imputed = y_train.fillna(-1)\n",
    "\n",
    "# Treinar o modelo de auto-treinamento\n",
    "self_training_model.fit(X_train_transformed, y_train_imputed)\n",
    "\n",
    "y_train_imputed = y_train_imputed.astype(float)\n",
    "\n",
    "# Agora, o modelo está treinado e os labels foram preenchidos (imputados)\n",
    "y_train_completed = self_training_model.predict(X_train_transformed).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categoric features \n",
    "\n",
    "## Linear Regression\n",
    "def print_metrics(y_pred_lr, y_test_clean):\n",
    "    print(\"MAPE :\", mean_absolute_percentage_error(y_pred_lr, y_test_clean))\n",
    "    print(\"R2 :\", r2_score(y_pred_lr, y_test_clean))\n",
    "    print(\"MSE :\", mean_squared_error(y_pred_lr, y_test_clean))\n",
    "\n",
    "def train_test_models(X_train_transformed, y_train_completed):\n",
    "\n",
    "    print(\"\\n -------------------- Linear Regression -------------------- \\n\")\n",
    "    lr_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", LinearRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lr_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_lr = lr_pipeline.predict(X_test_transformed)\n",
    "    print_metrics(y_pred_lr, y_test_clean)\n",
    "\n",
    "    ## Ridge Regression\n",
    "\n",
    "    print(\"\\n -------------------- Ridge Regression -------------------- \\n\")\n",
    "    ridge_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Ridge Regressor\", Ridge())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ridge_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_ridge = ridge_pipeline.predict(X_test_transformed)\n",
    "    print_metrics(y_pred_ridge, y_test_clean)\n",
    "\n",
    "    ## Lasso Regression\n",
    "\n",
    "    print(\"\\n -------------------- Lasso Regression -------------------- \\n\")\n",
    "    lasso_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Lasso Regressor\", Lasso())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lasso_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_lasso = lasso_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_lasso, y_test_clean)\n",
    "\n",
    "    ## ElasticNet Regression\n",
    "\n",
    "    print(\"\\n -------------------- ElasticNet Regression -------------------- \\n\")\n",
    "    ElasticNet_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", ElasticNet())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ElasticNet_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_ElasticNet = ElasticNet_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_ElasticNet, y_test_clean)\n",
    "\n",
    "    ## Decision Tree Regression\n",
    "\n",
    "    print(\"\\n -------------------- Decision Tree Regression -------------------- \\n\")\n",
    "    tree_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", DecisionTreeRegressor())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    tree_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_tree = tree_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_tree, y_test_clean)\n",
    "\n",
    "    ## Random Forest Regression\n",
    "\n",
    "    print(\"\\n -------------------- Random Forest Regression -------------------- \\n\")\n",
    "    RF_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", RandomForestRegressor())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    RF_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_RF = RF_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_RF, y_test_clean)\n",
    "\n",
    "    ## Gradient Boosting Regression\n",
    "\n",
    "    print(\"\\n -------------------- Gradient Boosting Regression -------------------- \\n\")\n",
    "    gb_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", GradientBoostingRegressor())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    gb_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_gb = gb_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_gb, y_test_clean)\n",
    "\n",
    "train_test_models(X_train_transformed, y_train_completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo XGBoost\n",
    "xbg_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"XGB\", xgb.XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "        ]\n",
    "    )\n",
    "xbg_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "\n",
    "y_pred_xgb = xbg_pipeline.predict(X_test_transformed)\n",
    "\n",
    "print_metrics(y_pred_xgb, y_test_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
