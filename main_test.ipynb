{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellima/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/gabriellima/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/imputer.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.numeric_features] = X[self.numeric_features].apply(pd.to_numeric, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler # it is not affected by outliers.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, RFECV\n",
    "# from imputer import create_full_pipeline\n",
    "from imputer import create_full_pipeline, HotEncoderCategorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "data_original = pd.read_csv('Assets/Data/welddb.csv', delimiter='\\s+', header=None)\n",
    "\n",
    "data = data_original.copy().replace({\"N\": np.nan})\n",
    "\n",
    "# Name the columns\n",
    "data.columns = [\n",
    "    'Carbon concentration (weight%)', \n",
    "    'Silicon concentration (weight%)', \n",
    "    'Manganese concentration (weight%)', \n",
    "    'Sulphur concentration (weight%)', \n",
    "    'Phosphorus concentration (weight%)', \n",
    "    'Nickel concentration (weight%)', \n",
    "    'Chromium concentration (weight%)', \n",
    "    'Molybdenum concentration (weight%)', \n",
    "    'Vanadium concentration (weight%)', \n",
    "    'Copper concentration (weight%)', \n",
    "    'Cobalt concentration (weight%)', \n",
    "    'Tungsten concentration (weight%)', \n",
    "    'Oxygen concentration (ppm by weight)', \n",
    "    'Titanium concentration (ppm by weight)', \n",
    "    'Nitrogen concentration (ppm by weight)', \n",
    "    'Aluminium concentration (ppm by weight)', \n",
    "    'Boron concentration (ppm by weight)', \n",
    "    'Niobium concentration (ppm by weight)', \n",
    "    'Tin concentration (ppm by weight)', \n",
    "    'Arsenic concentration (ppm by weight)', \n",
    "    'Antimony concentration (ppm by weight)', \n",
    "    'Current (A)', \n",
    "    'Voltage (V)', \n",
    "    'AC or DC', \n",
    "    'Electrode positive or negative', \n",
    "    'Heat input (kJ/mm)', \n",
    "    'Interpass temperature (°C)', \n",
    "    'Type of weld', \n",
    "    'Post weld heat treatment temperature (°C)', \n",
    "    'Post weld heat treatment time (hours)', \n",
    "    'Yield strength (MPa)', \n",
    "    'Ultimate tensile strength (MPa)', \n",
    "    'Elongation (%)', \n",
    "    'Reduction of Area (%)', \n",
    "    'Charpy temperature (°C)', \n",
    "    'Charpy impact toughness (J)', \n",
    "    'Hardness (kg/mm2)', \n",
    "    '50% FATT', \n",
    "    'Primary ferrite in microstructure (%)', \n",
    "    'Ferrite with second phase (%)', \n",
    "    'Acicular ferrite (%)', \n",
    "    'Martensite (%)', \n",
    "    'Ferrite with carbide aggregate (%)', \n",
    "    'Weld ID'\n",
    "]\n",
    "\n",
    "# Definição das colunas categóricas e numéricas\n",
    "categoric_features = ['AC or DC', 'Electrode positive or negative', 'Type of weld']\n",
    "numeric_features = ['Sulphur concentration (weight%)', 'Nickel concentration (weight%)', \n",
    "                    'Silicon concentration (weight%)', 'Phosphorus concentration (weight%)', \n",
    "                    'Titanium concentration (ppm by weight)', 'Nitrogen concentration (ppm by weight)', \n",
    "                    'Oxygen concentration (ppm by weight)', 'Voltage (V)', 'Heat input (kJ/mm)']\n",
    "\n",
    "# Separação dos dados em treino e teste\n",
    "X = data.drop(columns = [\"Yield strength (MPa)\", \"Weld ID\"])\n",
    "y = data[\"Yield strength (MPa)\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Criando o pipeline com as features necessárias\n",
    "percent_n_sorted = X_train.isna().mean().sort_values(ascending=False)\n",
    "full_pipeline = create_full_pipeline()\n",
    "\n",
    "# Dropping missing values in test\n",
    "X_test_clean = X_test[~y_test.isna()]\n",
    "y_test_clean = y_test.dropna().astype(float)\n",
    "\n",
    "# Aplicando o pipeline nos dados de treino\n",
    "X_train_transformed = X_train.copy()\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train_transformed)\n",
    "\n",
    "# Aplicando o pipeline nos dados de teste\n",
    "X_test_transformed = full_pipeline.transform(X_test_clean)\n",
    "\n",
    "# hotencoder = HotEncoderCategorical(X_train_transformed)\n",
    "# X_train_transformed = hotencoder.fit_transform(X_train_transformed)\n",
    "# X_test_transformed = hotencoder.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um modelo base (nesse caso, um RandomForest)\n",
    "# base_model = RandomForestClassifier()\n",
    "base_model = LabelSpreading(kernel='knn', n_neighbors=7)\n",
    "\n",
    "# Criar o modelo de auto-treinamento\n",
    "self_training_model = SelfTrainingClassifier(base_model)\n",
    "\n",
    "# X_train contém todas as variáveis explicativas\n",
    "# y_train contém os labels, mas com valores NaN para os rótulos faltantes\n",
    "# Importante: O SelfTrainingClassifier trata os valores faltantes como -1, então convertemos NaN para -1\n",
    "y_train_imputed = y_train.fillna(-1)\n",
    "\n",
    "# Treinar o modelo de auto-treinamento\n",
    "self_training_model.fit(X_train_transformed, y_train_imputed)\n",
    "\n",
    "y_train_imputed = y_train_imputed.astype(float)\n",
    "\n",
    "# Agora, o modelo está treinado e os labels foram preenchidos (imputados)\n",
    "y_train_completed = self_training_model.predict(X_train_transformed).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368186</td>\n",
       "      <td>0.755089</td>\n",
       "      <td>0.104193</td>\n",
       "      <td>-0.222542</td>\n",
       "      <td>-0.409326</td>\n",
       "      <td>0.402424</td>\n",
       "      <td>0.638008</td>\n",
       "      <td>-0.520152</td>\n",
       "      <td>-2.798737</td>\n",
       "      <td>0.755089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.021843</td>\n",
       "      <td>-0.082653</td>\n",
       "      <td>0.518459</td>\n",
       "      <td>0.564938</td>\n",
       "      <td>-0.425248</td>\n",
       "      <td>-0.554179</td>\n",
       "      <td>-1.489875</td>\n",
       "      <td>-0.520152</td>\n",
       "      <td>-0.145209</td>\n",
       "      <td>-0.082653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073331</td>\n",
       "      <td>-0.170836</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>-0.316289</td>\n",
       "      <td>-0.425248</td>\n",
       "      <td>-0.554179</td>\n",
       "      <td>0.367590</td>\n",
       "      <td>-0.069517</td>\n",
       "      <td>-0.145209</td>\n",
       "      <td>-0.170836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.884581</td>\n",
       "      <td>-0.347203</td>\n",
       "      <td>0.673808</td>\n",
       "      <td>-0.211292</td>\n",
       "      <td>-0.401150</td>\n",
       "      <td>-0.541756</td>\n",
       "      <td>-1.489875</td>\n",
       "      <td>0.072789</td>\n",
       "      <td>2.508318</td>\n",
       "      <td>-0.347203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.095157</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.492567</td>\n",
       "      <td>-0.316289</td>\n",
       "      <td>-0.425248</td>\n",
       "      <td>-0.554179</td>\n",
       "      <td>0.403055</td>\n",
       "      <td>-0.057658</td>\n",
       "      <td>-0.145209</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>0.199697</td>\n",
       "      <td>-0.347203</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>-0.256291</td>\n",
       "      <td>-0.412339</td>\n",
       "      <td>0.514235</td>\n",
       "      <td>0.505016</td>\n",
       "      <td>0.072789</td>\n",
       "      <td>2.508318</td>\n",
       "      <td>-0.347203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>0.368186</td>\n",
       "      <td>-0.259020</td>\n",
       "      <td>-1.708218</td>\n",
       "      <td>-0.248791</td>\n",
       "      <td>0.521478</td>\n",
       "      <td>2.054738</td>\n",
       "      <td>1.435965</td>\n",
       "      <td>-0.520152</td>\n",
       "      <td>-0.808591</td>\n",
       "      <td>-0.259020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>-1.232453</td>\n",
       "      <td>1.769198</td>\n",
       "      <td>1.398773</td>\n",
       "      <td>-0.297540</td>\n",
       "      <td>-0.386519</td>\n",
       "      <td>-0.554179</td>\n",
       "      <td>1.772880</td>\n",
       "      <td>0.428554</td>\n",
       "      <td>-0.145209</td>\n",
       "      <td>1.769198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>0.073331</td>\n",
       "      <td>0.975548</td>\n",
       "      <td>1.062182</td>\n",
       "      <td>-0.316289</td>\n",
       "      <td>-0.425248</td>\n",
       "      <td>-0.554179</td>\n",
       "      <td>0.434086</td>\n",
       "      <td>-0.520152</td>\n",
       "      <td>1.181554</td>\n",
       "      <td>0.975548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>0.199697</td>\n",
       "      <td>-0.259020</td>\n",
       "      <td>0.389001</td>\n",
       "      <td>-0.260041</td>\n",
       "      <td>-0.412339</td>\n",
       "      <td>-0.541756</td>\n",
       "      <td>0.372023</td>\n",
       "      <td>0.072789</td>\n",
       "      <td>2.508318</td>\n",
       "      <td>-0.259020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.368186  0.755089  0.104193 -0.222542 -0.409326  0.402424  0.638008   \n",
       "1    -1.021843 -0.082653  0.518459  0.564938 -0.425248 -0.554179 -1.489875   \n",
       "2     0.073331 -0.170836  0.337218 -0.316289 -0.425248 -0.554179  0.367590   \n",
       "3     1.884581 -0.347203  0.673808 -0.211292 -0.401150 -0.541756 -1.489875   \n",
       "4    -0.095157  0.005531  0.492567 -0.316289 -0.425248 -0.554179  0.403055   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1151  0.199697 -0.347203  0.337218 -0.256291 -0.412339  0.514235  0.505016   \n",
       "1152  0.368186 -0.259020 -1.708218 -0.248791  0.521478  2.054738  1.435965   \n",
       "1153 -1.232453  1.769198  1.398773 -0.297540 -0.386519 -0.554179  1.772880   \n",
       "1154  0.073331  0.975548  1.062182 -0.316289 -0.425248 -0.554179  0.434086   \n",
       "1155  0.199697 -0.259020  0.389001 -0.260041 -0.412339 -0.541756  0.372023   \n",
       "\n",
       "            7         8         9   ...   30   31   32   33   34   35   36  \\\n",
       "0    -0.520152 -2.798737  0.755089  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1    -0.520152 -0.145209 -0.082653  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "2    -0.069517 -0.145209 -0.170836  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3     0.072789  2.508318 -0.347203  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "4    -0.057658 -0.145209  0.005531  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1151  0.072789  2.508318 -0.347203  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1152 -0.520152 -0.808591 -0.259020  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1153  0.428554 -0.145209  1.769198  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1154 -0.520152  1.181554  0.975548  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1155  0.072789  2.508318 -0.259020  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "       37   38   39  \n",
       "0     0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  \n",
       "...   ...  ...  ...  \n",
       "1151  0.0  0.0  0.0  \n",
       "1152  0.0  0.0  0.0  \n",
       "1153  0.0  0.0  0.0  \n",
       "1154  0.0  0.0  0.0  \n",
       "1155  0.0  0.0  0.0  \n",
       "\n",
       "[1156 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1156, 40)\n",
      "(244, 39)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)\n",
    "print(X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- Linear Regression -------------------- \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 39 features, but LinearRegression is expecting 40 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m     y_pred_gb \u001b[38;5;241m=\u001b[39m gb_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test_transformed)\n\u001b[1;32m    103\u001b[0m     print_metrics(y_pred_gb, y_test_clean)\n\u001b[0;32m--> 105\u001b[0m \u001b[43mtrain_test_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_completed\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mtrain_test_models\u001b[0;34m(X_train_transformed, y_train_completed)\u001b[0m\n\u001b[1;32m     12\u001b[0m lr_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m     13\u001b[0m     [\n\u001b[1;32m     14\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m, LinearRegression())\n\u001b[1;32m     15\u001b[0m     ]\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m lr_pipeline\u001b[38;5;241m.\u001b[39mfit(X_train_transformed, y_train_completed)\n\u001b[0;32m---> 19\u001b[0m y_pred_lr \u001b[38;5;241m=\u001b[39m \u001b[43mlr_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m print_metrics(y_pred_lr, y_test_clean)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m## Ridge Regression\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:601\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[1;32m    604\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:285\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    283\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 285\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/CentraleSupelec/Mention/ApprAutomatique/Project/Welding-Quality-Prediction/.venv/lib/python3.11/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 39 features, but LinearRegression is expecting 40 features as input."
     ]
    }
   ],
   "source": [
    "# Categoric features \n",
    "\n",
    "## Linear Regression\n",
    "def print_metrics(y_pred_lr, y_test_clean):\n",
    "    print(\"MAPE :\", mean_absolute_percentage_error(y_pred_lr, y_test_clean))\n",
    "    print(\"R2 :\", r2_score(y_pred_lr, y_test_clean))\n",
    "    print(\"MSE :\", mean_squared_error(y_pred_lr, y_test_clean))\n",
    "\n",
    "def train_test_models(X_train_transformed, y_train_completed):\n",
    "\n",
    "    print(\"\\n -------------------- Linear Regression -------------------- \\n\")\n",
    "    lr_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", LinearRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lr_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_lr = lr_pipeline.predict(X_test_transformed)\n",
    "    print_metrics(y_pred_lr, y_test_clean)\n",
    "\n",
    "    ## Ridge Regression\n",
    "\n",
    "    print(\"\\n -------------------- Ridge Regression -------------------- \\n\")\n",
    "    ridge_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Ridge Regressor\", Ridge())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ridge_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_ridge = ridge_pipeline.predict(X_test_transformed)\n",
    "    print_metrics(y_pred_ridge, y_test_clean)\n",
    "\n",
    "    ## Lasso Regression\n",
    "\n",
    "    print(\"\\n -------------------- Lasso Regression -------------------- \\n\")\n",
    "    lasso_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Lasso Regressor\", Lasso())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lasso_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_lasso = lasso_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_lasso, y_test_clean)\n",
    "\n",
    "    ## ElasticNet Regression\n",
    "\n",
    "    print(\"\\n -------------------- ElasticNet Regression -------------------- \\n\")\n",
    "    ElasticNet_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", ElasticNet())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ElasticNet_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_ElasticNet = ElasticNet_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_ElasticNet, y_test_clean)\n",
    "\n",
    "    ## Decision Tree Regression\n",
    "\n",
    "    print(\"\\n -------------------- Decision Tree Regression -------------------- \\n\")\n",
    "    tree_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", DecisionTreeRegressor())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    tree_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_tree = tree_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_tree, y_test_clean)\n",
    "\n",
    "    ## Random Forest Regression\n",
    "\n",
    "    print(\"\\n -------------------- Random Forest Regression -------------------- \\n\")\n",
    "    RF_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", RandomForestRegressor())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    RF_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_RF = RF_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_RF, y_test_clean)\n",
    "\n",
    "    ## Gradient Boosting Regression\n",
    "\n",
    "    print(\"\\n -------------------- Gradient Boosting Regression -------------------- \\n\")\n",
    "    gb_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"Regressor\", GradientBoostingRegressor())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    gb_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "    y_pred_gb = gb_pipeline.predict(X_test_transformed)\n",
    "\n",
    "    print_metrics(y_pred_gb, y_test_clean)\n",
    "\n",
    "train_test_models(X_train_transformed, y_train_completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo XGBoost\n",
    "xbg_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"XGB\", xgb.XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "        ]\n",
    "    )\n",
    "xbg_pipeline.fit(X_train_transformed, y_train_completed)\n",
    "\n",
    "y_pred_xgb = xbg_pipeline.predict(X_test_transformed)\n",
    "\n",
    "print_metrics(y_pred_xgb, y_test_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
